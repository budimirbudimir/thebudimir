# AI Model Configuration
# By default, uses Ollama (local) in development and GitHub Models in production

# Ollama Configuration (local development)
# URL where Ollama is running (default: http://localhost:11434)
# OLLAMA_URL=http://localhost:11434
# Model to use with Ollama (default: mistral-7b-instruct-v0.3-q4_k_m:custom)
# OLLAMA_MODEL=mistral-7b-instruct-v0.3-q4_k_m:custom

# GitHub Models Configuration (production)
# Personal Access Token for GitHub Models API
# Get your token from: https://github.com/settings/tokens
# Required scopes: None (public access to GitHub Models)
GH_MODELS_TOKEN=your_github_token_here
# Force GitHub Models in development (optional)
# USE_GH_MODELS=true

# Web Search Configuration
BRAVE_SEARCH_API_KEY=your_brave_search_api_key_here

BRAVE_SEARCH_API_KEY=your_brave_search_api_key_here

# Server configuration
PORT=3000
NODE_ENV=development

# Database Configuration (Turso)
# Production: Set both to use Turso Cloud
# Local: Leave empty to use local SQLite file
TURSO_DATABASE_URL=libsql://your-db-name.turso.io
TURSO_AUTH_TOKEN=your_turso_auth_token_here
# Optional: Custom local database path (default: ./data/local.db)
# DB_PATH=./data/local.db

# Frontend URL for CORS (production only)
# FRONTEND_URL=https://thebudimir.com

# Clerk Configuration
VITE_CLERK_PUBLISHABLE_KEY=your_clerk_publishable_key_here
CLERK_SECRET_KEY=your_clerk_secret_key_here

# LocalTunnel Configuration
OLLAMA_URL=your_tunnel_url_here